# app/streamlit/dashboard.py
import os
import sys
import pickle
import tempfile

import shap
import joblib
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt

import plotly.graph_objects as go
from sklearn.model_selection import train_test_split

# Add project root to sys.path for imports
sys.path.append(
    os.path.abspath(
        os.path.join(os.path.dirname(__file__), '../../')
    )
)

# Project-specific imports
from src.data.load import load_ecommerce_data
from src.data.preprocess import preprocess_data
from src.models.train import train_model
from src.models.evaluate import run_full_evaluation
from src.visualization.visualize import (
    evaluate_oof_predictions,
    evaluate_test_set_predictions,
    run_plot_threshold_metrics,
    run_plot_calibration_curve,
    run_plot_lift_gain_chart,
    plot_rfm_segments
)
from src.models.interpret.shap_analysis import calculate_shap_values
from src.visualization.explain_plots import plot_shap_global

# Streamlit and matplotlib configuration
st.set_page_config(page_title="Customer Conversion Analytics", layout="wide")
plt.style.use('ggplot')

# Feature columns
numerical_features = [
    'price', 'hour', 'is_weekend', 'total_clicks',
    'avg_session_time', 'purchase_freq', 'products_viewed',
    'price_range', 'session_duration', 'recency', 'frequency', 'monetary'
]
categorical_features = ['main_category', 'rfm_segment']
features = numerical_features + categorical_features

# Set joblib temp folder
os.environ["JOBLIB_TEMP_FOLDER"] = tempfile.gettempdir()

def main():
    # st.title("üõç Customer Conversion Prediction Dashboard")
    st.markdown("## üõçCustomer Conversion Prediction Dashboard")

    # --- Centralize features in session state
    if "features" not in st.session_state:
        st.session_state["features"] = features
    if "numerical_features" not in st.session_state:
        st.session_state["numerical_features"] = numerical_features
    if "categorical_features" not in st.session_state:
        st.session_state["categorical_features"] = categorical_features

    # --- Sidebar for Configuration only
    with st.sidebar:
        st.markdown("### ‚öôÔ∏è Configuration")
        with st.expander("üîß Model Parameters", expanded=False):
            st.markdown("**Used in:** üßπ Data Loading")
            sample_size_option = st.selectbox(
                "üìä Sample Size Option",
                options=["Custom", "None"],
                index=0
            )
            if sample_size_option == "Custom":
                sample_size = st.number_input(
                    "Enter custom sample size",
                    min_value=50000,
                    max_value=10000000,
                    value=100000,
                    step=50000
                )
            else:
                sample_size = None

            st.markdown("### üìÅ Data Split")
            test_size = st.slider(
                "Test Size (%)", min_value=10, max_value=40, value=20, step=1
            )
            val_size = st.slider(
                "Validation Size (%)", min_value=10, max_value=30, value=25, step=1
            )

            st.markdown("### üéØ Threshold")
            use_optimal_thr = st.checkbox("Use optimal threshold from cross-validation?", value=True)
            threshold = st.slider(
                "Classification Threshold", min_value=0.3, max_value=0.7, value=0.5, step=0.01,
                disabled=use_optimal_thr
            )

    # --- Tab Structure ---
    tab_titles = ["EDA", "Feature Engineering", "Training", "Evaluation", "SHAP", "Download"]
    tabs = st.tabs(tab_titles)

    # --- EDA Tab ---
    with tabs[0]:
        st.markdown("### üîç Exploratory Data Analysis")
        load_data_btn = st.button("üì• Load Data", key="eda_load")
        if load_data_btn:
            with st.spinner("Loading and preprocessing data..."):
                try:
                    st.session_state["raw_df"] = load_data(sample_size)
                    st.success("‚úÖ Data loaded and preprocessed.")
                except Exception as e:
                    st.error(f"‚ùå Failed to load data: {e}")

        # Only show EDA if data is loaded
        if "raw_df" in st.session_state:
            eda_btn = st.button("üìÇ Run EDA", key="eda_run")
            if eda_btn:
                with st.spinner("Preparing data for EDA..."):
                    try:
                        processed_df = preprocess_and_display(st.session_state["raw_df"])
                        st.session_state["processed_df"] = processed_df
                        st.success("‚úÖ Data preprocessed for EDA.")
                    except Exception as e:
                        st.error(f"‚ùå EDA preparation failed: {e}")
            if "processed_df" in st.session_state:
                if st.session_state["processed_df"].empty:
                    st.warning("üìå No data available for EDA. Please load and preprocess the data first.")
        else:
            st.info("Please load the data to begin EDA.")

    # --- Feature Engineering Tab ---
    with tabs[1]:
        st.header("üîß Feature Engineering")
        feature_engg_btn = st.button(" üîß Run Feature Engineering", key="feature_engg_btn")
        if feature_engg_btn:
            if "processed_df" in st.session_state and st.session_state["processed_df"] is not None:
                with st.spinner("Running feature engineering and RFM segmentation..."):
                    try:
                        feature_engineering_and_display()
                        st.success("‚úÖ Feature engineering and RFM segmentation completed!")
                    except Exception as e:
                        st.error(f"‚ùå Feature engineering failed: {e}")
            else:
                st.warning("‚ö†Ô∏è Please run EDA and preprocessing before feature engineering.")


    # --- Training Tab ---
    with tabs[2]:
        st.markdown("### üîß Model Training")
        train_model_btn = st.button("üîß Train Model", key="train_btn")
        def check_processed_data():
            if "processed_df" not in st.session_state or st.session_state["processed_df"] is None:
                st.error("‚ùå Please run EDA or preprocessing before training/evaluating the model.")
                return False
            return True

        if train_model_btn:
            if not check_processed_data():
                st.stop()
            final_threshold = st.session_state.optimal_threshold if use_optimal_thr and st.session_state.get("optimal_threshold") else threshold
            st.info(f"Using {'optimal' if use_optimal_thr else 'manual'} threshold: {final_threshold}")
            with st.spinner("Training model... please wait..."):
                try:
                    train_and_display_model(
                        st.session_state["processed_df"],
                        test_size,
                        val_size,
                        final_threshold
                    )
                    st.success("‚úÖ Model trained successfully!")
                except Exception as e:
                    st.error(f"‚ùå Training failed: {e}")

    # --- Evaluation Tab ---
    with tabs[3]:
        st.markdown("### üìà Model Evaluation")
        evaluation_btn = st.button("üìà Evaluate Model", key="eval_btn")
        if evaluation_btn:
            if st.session_state.get("model", None) is not None:
                for key, val in {
                    "show_oof": False,
                    "show_test": False,
                    "show_threshold_matrix": False,
                    "calibration_curve": False,
                    "lift_gain_charts": False,
                    "evaluation_started": True
                }.items():
                    st.session_state.setdefault(key, val)
            else:
                st.warning("‚ö†Ô∏è Please train the model first.")

        if st.session_state.get("evaluation_started", False):
            display_evaluation_plots(threshold)

    # --- SHAP Tab ---
    with tabs[4]:
        st.markdown("### üß† Generate SHAP Explanations")
        generate_shap_btn = st.button("üß† Generate SHAP", key="shap_btn")
        if generate_shap_btn:
            if st.session_state.get("model", None) is not None:
                selected_sample = st.selectbox("Select Sample for SHAP", options=range(0, 50, 5), index=2)
                st.session_state.selected_sample = selected_sample
                with st.spinner("Generating SHAP values..."):
                    try:
                        generate_and_display_shap(st.session_state["processed_df"])
                        st.success("‚úÖ SHAP explanation generated!")
                    except Exception as e:
                        st.error(f"‚ùå SHAP generation failed: {e}")
            else:
                st.warning("‚ö†Ô∏è Please train the model first to use SHAP.")

    # --- Download Tab ---
    with tabs[5]:
        st.markdown("### ‚¨áÔ∏è Download Model and Artifacts")
        download_btn = st.button("‚¨áÔ∏è Download Model", key="download_btn")
        if download_btn:
            if st.session_state.get("model", None) is not None:
                display_download_options()
            else:
                st.warning("‚ö†Ô∏è Please train the model before downloading.")

def load_data(sample_size):
    """Load and display raw data"""
    with st.spinner("Loading data..."):
        file_path = r"D:\Learnings\My_Projects\Datasets\eCommerce behavior data 2019-Nov\eCommerce behavior data 2019-Nov.parquet"
        raw_df = load_ecommerce_data(file_path, sample_size)

        st.write(f"Raw Data Shape: {raw_df.shape}")
        
        st.subheader("Raw Data Sample")
        st.dataframe(raw_df.head(), use_container_width=True)
            
        st.divider()
        st.subheader("Data Summary")
        st.write(f"Total Rows: {raw_df.shape[0]:,}")
        st.write(f"Columns: {raw_df.shape[1]}")
        st.write("Event Type Distribution:")
        st.bar_chart(raw_df['event_type'].value_counts())
            
        return raw_df

def preprocess_and_display(raw_df):
    """Preprocess data and display results with enhanced interaction"""
    with st.spinner("üîÑ Preprocessing data..."):
        processed_df, results, rmf_results = preprocess_data(raw_df)
        st.session_state.rmf_results = rmf_results

    # Basic stats section
    st.markdown("### üìä Data Overview")
    st.success("‚úÖ Data Preprocessed Successfully")
    st.write(f"**Total Rows:** {processed_df.shape[0]:,}")
    st.write(f"**Total Columns:** {processed_df.shape[1]}")
    st.divider()

    # Expandable section for data inspection
    with st.expander("üîç **Explore Processed Data**", expanded=False):
        st.subheader("üìà Summary Statistics")
        st.dataframe(processed_df.describe(), use_container_width=True)

        st.divider()
        st.subheader("‚è±Ô∏è Session Duration Distribution")
        fig, ax = plt.subplots()
        processed_df['session_duration'].hist(ax=ax, bins=30, color='skyblue', edgecolor='black')
        ax.set_title("Session Duration Histogram")
        ax.set_xlabel("Duration")
        ax.set_ylabel("Frequency")
        st.pyplot(fig)

    st.divider()

    # EDA Visualizations
    st.subheader("üìâ Exploratory Data Analysis (EDA)")
    render_evaluation_section(
        section_title="üìä EDA Visualizations",
        results=results,
        plot_titles=[
            "Event Type Distribution",
            "Top 10 Product Categories",
            "Top 10 Subcategories",
            "Hourly User Activity",
            "Daily Unique Visitors",
            "Feature Correlation Heatmap"

        ],
        error_message="‚ö†Ô∏è Failed to generate EDA visualizations"
    )
    # selected_eda_cols = ['event_type', 'category_code', 'event_time', 'user_id']
    # processed_df.drop(columns=selected_eda_cols, inplace=True)

    return processed_df

def feature_engineering_and_display():
    """Feature engineering and display results"""
    rmf_results = st.session_state.get("rmf_results")
    if rmf_results is not None:
        plot_titles = [
            "Frequency vs. Monetary by Segment",
            "Recency vs. Frequency by Segment",
            "Customer Count by Segment"
        ]
        render_evaluation_section(
            section_title="RFM Segmentation Visualizations",
            results=rmf_results,
            plot_titles=plot_titles,
            error_message="Error generating RFM segmentation plots"
        )
    else:
        st.info("No RFM data available. Please ensure feature engineering is complete.")
 
def train_and_display_model(model_df, test_size, val_size, threshold):
    # """Handle model training flow""")
    features = st.session_state["features"]
    numerical_features = st.session_state["numerical_features"]
    categorical_features = st.session_state["categorical_features"]
    
    X = model_df[features]
    y = model_df['target']
    
    # Split data
    X_train_val, X_test, y_train_val, y_test = train_test_split(
        X, y, test_size=test_size/100, stratify=y, random_state=42
    )
    X_train, X_val, y_train, y_val = train_test_split(
        X_train_val, y_train_val, test_size=val_size/100, stratify=y_train_val, random_state=42
    )
    
    # Map original DF to NumPy for all datasets
    # X_train = X_train[features].to_numpy()
    # X_val = X_val[features].to_numpy()
    # y_train = y_train.to_numpy()
    # y_val = y_val.to_numpy()
    # X_test = X_test[features].to_numpy()
    # y_test = y_test.to_numpy()

    X_train = X_train[features]
    X_val = X_val[features]
    X_test = X_test[features]


    # Train model
    model, y_proba, y_pred = train_model(
        X_train=X_train,
        y_train=y_train,
        X_val=X_val,
        y_val=y_val,
        X_test=X_test,
        threshold = threshold,
        numerical_features=numerical_features,
        categorical_features=categorical_features
    )
    
    # Display model info
    st.subheader("üéØ Model Architecture")

    class_names = ['Non-Target Customer', 'Target Customer']

    oof_predictions, y_train_oof, optimal_threshold, cv_results = run_full_evaluation(
        trained_model=model,
        X_train=X_train,
        y_train=y_train,
        X_test=X_test,
        y_test=y_test,
        class_labels=class_names,
        n_splits=5,
        early_stopping_rounds=20
    )

    st.write("### Model Evaluation Results")

    st.subheader("üìà Cross-Validation Summary")
    st.write(f"**Mean ROC AUC:** {cv_results['mean_auc']:.4f} ¬± {cv_results['std_auc']:.4f}")
    st.write(f"**Mean PR AUC:** {cv_results['mean_pr_auc']:.4f} ¬± {cv_results['std_pr_auc']:.4f}")
    st.write(f"**Mean F1 (0.5 thr):** {cv_results['mean_f1_score_thresh05']:.4f} ¬± {cv_results['std_f1_score_thresh05']:.4f}")

    st.write(f"**Optimal Threshold:** {optimal_threshold:.4f}")
    st.session_state.oof_predictions = oof_predictions
    st.session_state.y_train_oof = y_train_oof
    st.session_state.optimal_threshold = optimal_threshold

    # Store in session state
    st.session_state.model = model
    st.session_state.X_test = X_test
    st.session_state.y_test = y_test
    st.session_state.y_proba = y_proba
    st.session_state.y_pred = y_pred

def render_evaluation_section(
    section_title: str,
    results,
    plot_titles: list[str],
    error_message: str
):
    """Render a section for evaluation plots"""
    st.divider()
    st.subheader(section_title)
    try:
        figs = list(results) if isinstance(results, (tuple, list)) else [results]

        if len(figs) != len(plot_titles):
            st.warning(f"‚ö†Ô∏è Number of plots ({len(figs)}) and titles ({len(plot_titles)}) differ. Titles may not match figures.")

        for i, fig in enumerate(figs):
            st.subheader(plot_titles[i] if i < len(plot_titles) else f"Plot {i+1}")
            if isinstance(fig, go.Figure):
                st.plotly_chart(fig, use_container_width=True)
            elif isinstance(fig, plt.Figure):
                st.pyplot(fig)
            else:
                st.warning(f"Figure {i+1} is not a valid Plotly or Matplotlib figure. Skipping.")
    except Exception as e:
        st.error(f"{error_message}: {str(e)}")

def display_evaluation_plots(threshold):
    """Display evaluation plots based on session state"""
    st.markdown("### üîç Model Evaluation")

    required_keys = ["model", "oof_predictions", "y_train_oof", "X_test", "y_test"]
    for key in required_keys:
        if key not in st.session_state:
            st.warning(f"Session state missing required key: {key}. Please train and evaluate the model first.")
            return

    # UI Toggles
    st.session_state.show_oof = st.checkbox("Show OOF Evaluation Plots", value=st.session_state.get("show_oof", False))
    st.session_state.show_test = st.checkbox("Show Test Evaluation Plots", value=st.session_state.get("show_test", False))
    st.session_state.show_threshold_matrix = st.checkbox("Show Threshold Confusion Matrix Plots ", value=st.session_state.get("show_threshold_matrix", False))
    st.session_state.calibration_curve = st.checkbox("Show Calibration Curve for Test Data", value=st.session_state.get("calibration_curve", False))
    st.session_state.lift_gain_charts = st.checkbox("Show Lift and Gain Charts", value=st.session_state.get("lift_gain_charts", False))

    if st.session_state.show_oof:
        try:
            results = evaluate_oof_predictions(
                trained_model=st.session_state.model,
                oof_predictions=st.session_state.oof_predictions,
                y_train_oof=st.session_state.y_train_oof,
                class_labels=['Non-Target Customer', 'Target Customer'],
                optimal_threshold=threshold
            )
            render_evaluation_section(
                section_title="OOF Evaluation Plots",
                results=results,
                plot_titles=["OOF Confusion Matrix", "OOF ROC Curve", "OOF Precision-Recall (PR) Curve"],
                error_message="Failed to generate OOF evaluation plots"
            )
        except Exception as e:
            st.error(f"Failed to generate OOF evaluation plots: {str(e)}")

    if st.session_state.show_test:
        try:
            results = evaluate_test_set_predictions(
                trained_model=st.session_state.model,
                y_test=st.session_state.y_test,
                y_proba=st.session_state.y_proba,
                y_pred=st.session_state.y_pred,
                class_labels=['Non-Target Customer', 'Target Customer'],
            )
            render_evaluation_section(
                section_title="Test Evaluation Plots",
                results=results,
                plot_titles=["Test Confusion Matrix", "Test ROC Curve", "Test Precision-Recall (PR) Curve"],
                error_message="Failed to generate test evaluation plots"
            )
        except Exception as e:
            st.error(f"Failed to generate test evaluation plots: {str(e)}")

    if st.session_state.show_threshold_matrix:
        try:
            results = run_plot_threshold_metrics(
                trained_model=st.session_state.model,
                y_true=st.session_state.y_train_oof,
                y_pred_proba=st.session_state.oof_predictions,
                data_type="OOF Data",
                beta=1.0,
                optimal_metric='F1'
            )
            render_evaluation_section(
                section_title="Threshold Confusion Matrix Plots",
                results=results,
                plot_titles=["OOF Threshold Confusion Matrix"],
                error_message="Failed to generate threshold confusion matrix plots"
            )
        except Exception as e:
            st.error(f"Failed to generate threshold confusion matrix plots: {str(e)}")

    if st.session_state.calibration_curve:
        try:
            results = run_plot_calibration_curve(
                trained_model=st.session_state.model,
                X_test=st.session_state.X_test,
                y_true=st.session_state.y_test,
                test_proba=st.session_state.y_proba,
                y_train_oof=st.session_state.y_train_oof,
                oof_predictions=st.session_state.oof_predictions,
                data_type=["OOF Data", "Test Data"]
            )
            render_evaluation_section(
                section_title="Calibration Curve for OOF and Test Data",
                results=results,
                plot_titles=["OOF Calibration Curve", "Test Calibration Curve"],
                error_message="Failed to generate calibration curve"
            )
        except Exception as e:
            st.error(f"Failed to generate calibration curve: {str(e)}")

    if st.session_state.lift_gain_charts:
        try:
            results = run_plot_lift_gain_chart(
                trained_model=st.session_state.model,
                X_test=st.session_state.X_test,
                y_test=st.session_state.y_test,
                test_proba=st.session_state.y_proba,
                y_train_oof=st.session_state.y_train_oof,
                oof_predictions=st.session_state.oof_predictions,
                data_type="Test Data"
            )
            render_evaluation_section(
                section_title="Lift and Gain Charts",
                results=results,
                plot_titles=["OOF Lift Chart", "OOF Gain Chart", "Test Data Lift Chart", "Test Data Gain Chart"],
                error_message="Failed to generate lift and gain charts"
            )
        except Exception as e:
            st.error(f"Failed to generate lift and gain charts: {str(e)}")

def generate_and_display_shap(df):
    """Handle SHAP analysis"""
    model = st.session_state.model
    preprocessor = model.named_steps['preprocessor']
    xgb_model = model.named_steps['xgb']
    sample_idx = st.session_state.selected_sample
    
    # Calculate SHAP values
    shap_values, X_val_processed, feature_names = calculate_shap_values(
        model=xgb_model,
        preprocessor=preprocessor,
        data=df,
        model_type='xgb'
    )
    
    # Store in session state
    st.session_state.shap_values = shap_values
    st.session_state.feature_names = feature_names
    
    # Display plots
    st.markdown("### üìä SHAP Analysis")
    
    st.subheader("Global Feature Importance")
    fig = plot_shap_global(shap_values, feature_names, plot_type='bar')
    st.pyplot(fig)
        
    st.subheader("Feature Impact Distribution")
    fig = plot_shap_global(shap_values, feature_names, plot_type='dot')
    st.pyplot(fig)
        
    # Individual sample explanation
    st.subheader("üß† Individual Prediction Explanation")
    explain_sample(sample_idx, shap_values, X_val_processed, feature_names)

def explain_sample(sample_idx, shap_values, X_val, feature_names):
    """Display force plot for individual sample"""    
    # Generate force plot as HTML (JS-based)
    force_plot = shap.force_plot(
        base_value=shap_values.base_values[sample_idx],
        shap_values=shap_values.values[sample_idx],
        features=X_val[sample_idx],
        feature_names=feature_names,
        matplotlib=False  # <- Use JS-based for compatibility
    )

    # Render force plot in Streamlit using HTML
    shap_html = f"<head>{shap.getjs()}</head><body>{force_plot.html()}</body>"
    st.components.v1.html(shap_html, height=500)

    html_data = shap_force_plot_to_html(force_plot)
    st.download_button(
        label="Download Explanation (HTML)",
        data=html_data,
        file_name=f"shap_explanation_{sample_idx}.html",
        mime="text/html"
    )

def shap_force_plot_to_html(force_plot_obj):
    """
    Convert a SHAP force_plot object to HTML string using its `html()` method.
    """
    try:
        return force_plot_obj.html()
    except AttributeError:
        raise RuntimeError("Invalid SHAP force plot object. Ensure you are using shap.force_plot().")

def display_download_options():
    st.markdown("### üì§ Download Assets")
    col1, col2 = st.columns(2)
    with col1:
        st.download_button(
            label="Download Model",
            data=pickle.dumps(st.session_state.model),
            file_name="conversion_model.pkl",
            mime="application/octet-stream"
        )
    with col2:
        if st.session_state.get("shap_values", None) is not None:
            csv = save_top_features_to_csv()
            st.download_button(
                label="Download Top Features",
                data=csv,
                file_name="top_features.csv",
                mime="text/csv"
            )
        else:
            st.info("Run SHAP analysis first to download top features.")

def save_top_features_to_csv():
    """Convert top features to CSV"""
    shap_df = pd.DataFrame(st.session_state.shap_values.values, 
                          columns=st.session_state.feature_names)
    top_features = shap_df.abs().mean().sort_values(ascending=False).head(10).index
    return shap_df[top_features].to_csv(index=False).encode('utf-8')


if __name__ == "__main__":
    main()